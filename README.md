**Author**        | [Karthik Arjun](https://www.linkedin.com/in/karthik-arjun-a5b4a258/)  
------------------|-------------------------------------------------------------  
**Book Reference**| *Build a Large Language Model* by Sebastian Raschka  
**Lesson**        | L1 - Tokenization, Vocabulary, Encoding & Decoding  
**Next Lesson**   | L2 - Tensors & Embeddings (Coming Soon)

---

## ðŸ“˜ About

This is **ðŸ§  L1 - Basics of Tokenization & Vocabulary (LLM Series)** in my learning series for building a Large Language Model from scratch. It covers how to work with text data and convert it into tokens and numeric IDs.

---

## âœ… What This Lesson Covers

| Step  | Task                               | Description |
|-------|------------------------------------|-------------|
| 1     | Download Text File                 | Download `the-verdict.txt` from GitHub |
| 2     | Tokenize Text                      | Use regex to split into words & punctuation |
| 3     | Build Vocabulary                   | Create unique token â†’ ID mapping |
| 4     | Encode Input                       | Convert `"I love Jack"` into token IDs |
| 5     | Decode                             | Convert token IDs back to readable text |

---

## ðŸ§° Requirements

- Python 3.x  
- Uses built-in modules only: `os`, `re`, `urllib`
